{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a8b93a-31e4-460e-8ac5-449eb1a7782b",
   "metadata": {},
   "source": [
    "# Ideas for features\n",
    "\n",
    "1. Timestamp with highest percentage of sub users participating\n",
    "1. Cluster chat via [brown clustering](https://towardsdatascience.com/a-friendly-introduction-to-text-clustering-fa996bcefd04) or [something like that](https://www.researchgate.net/publication/320849253_Stream_Clustering_of_Chat_Messages_with_Applications_to_Twitch_Streams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c111f92-ef20-4ce4-a038-a38cb621e5b8",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "1. ~~Calculate what % of the emojis used were in a specific chunk~~\n",
    "1. ~~Find number of emojis used at time stamp divided by number of unique users at that timestamp~~\n",
    "1. ~~Jsonify results~~\n",
    "1. ~~Integrate to pillaralgos~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e23489",
   "metadata": {},
   "source": [
    "This algorithm uses emoticon labels to \"categorize\" timestamps they occur at. Whichever emoticon is spammed the most is the dominant \"sentiment\" of that timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e8e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from icecream import ic\n",
    "\n",
    "from pillaralgos_dev import dev_helpers as dev\n",
    "from pillaralgos.helpers import data_handler\n",
    "from pillaralgos import algo3_6, algo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b6c317b-9220-4796-a519-b6548a366f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('data/med_920260466.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6481e01d-aa5e-48c9-afe1-68f96db647f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = algo3_6.emoticonExtractor(data)\n",
    "res = ee.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "211efb30-3383-4490-b26a-42ad7195b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = algo4.sentimentRanker(data)\n",
    "res = ee.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84aedc51-7354-41e0-b31f-3555295fa277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'startTime': 10951.206, 'endTime': 11069.19},\n",
       " {'startTime': 32812.109, 'endTime': 32926.819},\n",
       " {'startTime': 18905.332, 'endTime': 19022.687},\n",
       " {'startTime': 20869.266, 'endTime': 20988.664},\n",
       " {'startTime': 8331.312, 'endTime': 8451.249},\n",
       " {'startTime': 33206.057, 'endTime': 33320.441},\n",
       " {'startTime': 7595.537, 'endTime': 7715.326},\n",
       " {'startTime': 32946.793, 'endTime': 33065.442},\n",
       " {'startTime': 5924.051, 'endTime': 6038.683},\n",
       " {'startTime': 18784.848, 'endTime': 18898.001}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff311ae-ee0f-41dd-b870-123cc2b55660",
   "metadata": {},
   "source": [
    "# Stream formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c405a99-0b84-471f-92c7-5cd1918955c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data\n",
    "data = json.load(open('data/lg_983754539.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5e59fb-0a96-4213-83fa-db77e1c71037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Contains one class `emoticonExtractor` that returns a df of top emoticons used,\n",
    "including the video's ID, and the emoticon's id, name, number of uses. Plus a blank\n",
    "\"label\" column to be filled out by little label-monkeys.\n",
    "\n",
    "\"Top emoticons used\" is defined as `emoticon count in dataset` >= `mean emoticon count in dataset`\n",
    "\n",
    "HOW TO:\n",
    "    ee = emoticonExtractor(data, limit='mean')\n",
    "    vid_emos_df = ee.run()\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from pillaralgos.helpers import data_handler as dh\n",
    "\n",
    "\n",
    "class emoticonExtractor:\n",
    "    def __init__(self, data, sort_by='perc_then_ratio', limit=10, chunk_length=2, save_json=False):\n",
    "        \"\"\"\n",
    "        Gets data ready for emo extraction. Initializes dicts, lists, etc.\n",
    "\n",
    "        input\n",
    "        -----\n",
    "        data: list\n",
    "            List of dictionaries, a json file opened with json.load(open(file))\n",
    "        sort_by: str\n",
    "            Options: \n",
    "                \"perc_emoji_of_stream\" - percent of emoticons from stream sent at timestamp\n",
    "                \"emoji_user_ratio\" - number of unique users participating compared to number of emoticons sent\n",
    "                \"perc_then_ratio\" - first sort with \"perc_emoji_of_stream\", then by \"emoji_user_ratio\"\n",
    "                \"ratio_then_perc\" - first sort with \"emoji_user_ratio\", then by \"perc_emoji_of_stream\"\n",
    "\n",
    "            Return timestamps with the highest `sort_by` value\n",
    "        limit: int, None\n",
    "            int: Return only the top X timestamps (using df.head(X))\n",
    "            None: Return all timestamps\n",
    "        \"\"\"\n",
    "        self.big_df = dh.organize_twitch_chat(data) # organize\n",
    "        self.first_stamp, self.chunks_list = dh.get_chunks(self.big_df, min_=chunk_length) # first timestamp + list of X min chunks\n",
    "        self.vid_id = data[0][\"content_id\"]\n",
    "\n",
    "        self.sort_by = sort_by\n",
    "        self.limit = limit\n",
    "        self.save_json = save_json\n",
    "\n",
    "    def run(self):\n",
    "        if type(self.big_df) == pd.DataFrame:\n",
    "            results = self.thalamus()\n",
    "            self.results = results\n",
    "            # results_jsonified sorts by top calc\n",
    "            json_results = dh.results_jsonified(results, self.first_stamp, self.sort_by)\n",
    "            if type(self.limit) == int:\n",
    "                # grab only the top X most used\n",
    "                json_results = json_results[:self.limit]\n",
    "\n",
    "            if self.save_json:\n",
    "                dh.save_json(json_results, f\"algo3.6_{self.sort_by}\")\n",
    "\n",
    "            return json_results\n",
    "        else:\n",
    "            return np.array([]) # this is an empty numpy array if it is not a DF.\n",
    "\n",
    "    def thalamus(self):\n",
    "        \"\"\"\n",
    "        Coordinates all functions to return a dataset of top emojis used\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        self.pd = pd\n",
    "\n",
    "        big_emo = 0\n",
    "        big_df_formatted = self.format_df_for_emo(self.big_df)\n",
    "        # get a count total number of emojis in stream\n",
    "        for idx, row in big_df_formatted.iterrows():\n",
    "            num_emo = self.emo_counter(row)\n",
    "            big_emo += num_emo\n",
    "\n",
    "        # get count of total emoticon per chunk and number of users per chunk\n",
    "        chunk_data = pd.DataFrame(columns=['start','end','num_emoji',])\n",
    "        for chunk in self.chunks_list:\n",
    "            time_range = (chunk.iloc[0,0],chunk.iloc[-1,0])\n",
    "            start = time_range[0] # very first timestamp of chunk\n",
    "            end = time_range[1] # very last timestamp of chunk\n",
    "            num_user = self.user_counter(chunk)\n",
    "            \n",
    "            chunk_emo = 0\n",
    "            chunk_formatted = self.format_df_for_emo(chunk)\n",
    "            try:\n",
    "                if chunk_formatted.empty:\n",
    "                    chunk_emo += 0\n",
    "                else:\n",
    "                    for idx, row in chunk_formatted.iterrows():\n",
    "                        num_emo = self.emo_counter(row)\n",
    "                        chunk_emo += num_emo\n",
    "            except AttributeError as a:\n",
    "                chunk_emo += 0\n",
    "\n",
    "            chunk_data = chunk_data.append({\n",
    "                'start':start,'end':end,'num_emoji':chunk_emo, 'num_user':num_user\n",
    "            }, ignore_index=True)\n",
    "        chunk_data['perc_emoji_of_stream'] = chunk_data['num_emoji'] / big_emo\n",
    "        chunk_data['emoji_user_ratio'] = chunk_data['num_emoji'] / chunk_data['num_user']\n",
    "        \n",
    "        result = self.finalize(chunk_data)\n",
    "        return result\n",
    "\n",
    "    ### ACTUAL FUNCTIONS ###\n",
    "\n",
    "    def format_df_for_emo(self, dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "        '''\n",
    "        Extracts emojis to make them accessible to counter\n",
    "        '''\n",
    "        import pandas as pd\n",
    "        \n",
    "        # check whether dataframe has any emoticons\n",
    "        body_has_emo = dataframe[~dataframe[\"emoticons\"].isna()].reset_index(\n",
    "            drop=True)\n",
    "        if len(body_has_emo.index) == 0:\n",
    "            return None\n",
    "        \n",
    "        # emoticons col contains _id, begin, end. Here we extract just the _id and\n",
    "        # put it into a list\n",
    "        body_has_emo[\"emo_id_list\"] = body_has_emo[\"emoticons\"].apply(\n",
    "            lambda my_list: self.emo_extractor(my_list)\n",
    "        )\n",
    "\n",
    "        emo_data = body_has_emo[[\"emo_id_list\", \"body\"]]\n",
    "\n",
    "        return emo_data\n",
    "\n",
    "\n",
    "    def finalize(self, dataframe: pd.DataFrame) -> list:\n",
    "        \"\"\"\n",
    "        Sorts dataframe by given class parameter and jsonifies the result\n",
    "        \"\"\"\n",
    "        if self.sort_by in [\"perc_emoji_of_stream\", \"emoji_user_ratio\"]:\n",
    "            self.sort_by = self.sort_by\n",
    "        elif self.sort_by == \"perc_then_ratio\":\n",
    "            self.sort_by = ['perc_emoji_of_stream', 'emoji_user_ratio']\n",
    "        elif self.sort_by == \"ratio_then_perc\":\n",
    "            self.sort_by = ['emoji_user_ratio', 'perc_emoji_of_stream']\n",
    "        else:\n",
    "            self.sort_by = ['perc_emoji_of_stream', 'emoji_user_ratio']\n",
    "            print(\"Invalid sort_by value, sorting by default value\")\n",
    "\n",
    "        dataframe[\"vid_id\"] = self.vid_id\n",
    "        return dataframe\n",
    "\n",
    "    ### HELPER FUNCTIONS ###\n",
    "    def emo_extractor(self, my_list):\n",
    "        \"\"\"\n",
    "        Helper function to grab emoticon id\n",
    "        \"\"\"\n",
    "        return [emo_dict[\"_id\"] for emo_dict in my_list]\n",
    "\n",
    "    def loc_extractor(self, my_list):\n",
    "        \"\"\"\n",
    "        Helper function to grab index location of emoticon in the body\n",
    "        \"\"\"\n",
    "        return [[emo_dict[\"begin\"], emo_dict[\"end\"]] for emo_dict in my_list]\n",
    "\n",
    "    def user_counter(self, dataframe):\n",
    "        '''\n",
    "        Counts the number of unique users in the dataframe\n",
    "        '''\n",
    "        return len(dataframe['_id'].unique())\n",
    "        \n",
    "    def emo_counter(self, row):\n",
    "        '''\n",
    "        Counts the number of times an emoticon occurs in the row\n",
    "        \n",
    "        This is a more accessible way of counting, vs making of emoji list and then\n",
    "        counting the occurrances in there\n",
    "        '''\n",
    "        # for each emoji_id in the list\n",
    "        counter = 0\n",
    "        for emoji_id in row['emo_id_list']:\n",
    "            counter += 1\n",
    "        return counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3af81f-bf32-4d84-90c3-bebb77e1f7dc",
   "metadata": {},
   "source": [
    "# Bug Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e5dae-e931-41c4-8e16-ed2fa16bdf6f",
   "metadata": {},
   "source": [
    "Check that all parameters work as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23981e2f-4cc0-4c25-a6c7-b8fbece03f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_diff(results):\n",
    "    for res in results:\n",
    "        print(res['endTime'] - res['startTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46dfd8c6-38f9-49f6-a97f-bdcd82aff7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_length(results, chunk_length):\n",
    "    time_check = []\n",
    "    # convert to seconds\n",
    "    setting = chunk_length * 60\n",
    "\n",
    "    # some wiggle room\n",
    "    setting_plus = round(setting + (setting*0.1))\n",
    "    setting_minus = round(setting - (setting*0.1))\n",
    "\n",
    "    for res in results:\n",
    "        time = res['endTime'] - res['startTime'] # get total seconds\n",
    "\n",
    "        if (time >= setting_minus) & (time <= setting_plus):\n",
    "            time_check.append(True)\n",
    "        else:\n",
    "            time_check.append(False)\n",
    "    \n",
    "    # if at least half the results passed, then its good\n",
    "    if sum(time_check) >= round(len(time_check) / 2):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2081cde-0f91-443e-a1d9-917b15a6e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_limit(results: list, limit: int) -> bool:\n",
    "    '''\n",
    "    Checks whether the length of result == limit\n",
    "    '''\n",
    "    # sometimes algo doesn't find enough chunks, \n",
    "    # so results may be less than limit\n",
    "    if len(results) <= limit:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e94d024-e879-4fa3-9615-2067d4b88797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sort(results, dataframe, sort_by):\n",
    "    '''\n",
    "    Checks whether the results were sorted correctly\n",
    "    '''\n",
    "    import datetime as dt\n",
    "    \n",
    "    limit = len(results)\n",
    "    if sort_by in [\"perc_emoji_of_stream\", \"emoji_user_ratio\"]:\n",
    "        sort_by = sort_by\n",
    "    elif sort_by == \"perc_then_ratio\":\n",
    "        sort_by = ['perc_emoji_of_stream', 'emoji_user_ratio']\n",
    "    elif sort_by == \"ratio_then_perc\":\n",
    "        sort_by = ['emoji_user_ratio', 'perc_emoji_of_stream']\n",
    "    else:\n",
    "        sort_by = ['perc_emoji_of_stream', 'emoji_user_ratio']\n",
    "        print(\"Invalid sort_by value, sorting by default value\")\n",
    "\n",
    "    dataframe = dataframe.sort_values(sort_by, ascending = False).head(limit)\n",
    "    \n",
    "    starts = []\n",
    "    ends = []\n",
    "    \n",
    "    for idx, row in dataframe.iterrows():\n",
    "        og = row[\"first_sec\"]\n",
    "        start = row[\"start\"]\n",
    "        end = row[\"end\"]\n",
    "\n",
    "        start_sec = dt.timedelta.total_seconds(\n",
    "            start - og\n",
    "        )  # find difference between first sec and given timestamp, convert that to seconds\n",
    "        end_sec = dt.timedelta.total_seconds(end - og)\n",
    "\n",
    "        starts.append(start_sec)\n",
    "        ends.append(end_sec)\n",
    "    \n",
    "    passed = []\n",
    "    for i in range(len(results)):\n",
    "        res = results[i]\n",
    "        if (res['startTime'] == starts[i]) & (res['endTime'] == ends[i]):\n",
    "            passed.append(True)\n",
    "        else:\n",
    "            passed.append(False)\n",
    "    \n",
    "    if len(passed) == sum(passed):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ce42627-ef10-4b5a-b1f0-9bbfce939f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| test_limit(res, limit=limit): True\n",
      "ic| test_length(res, chunk_length): True\n",
      "ic| test_sort(res, ee.results,sort_by=sort_by): True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_length = 5\n",
    "limit = 7\n",
    "sort_by = 'emoji_user_ratio'\n",
    "\n",
    "ee = emoticonExtractor(data, sort_by=sort_by, chunk_length = chunk_length, limit = limit)\n",
    "res = ee.run()\n",
    "\n",
    "ic(test_limit(res, limit=limit))\n",
    "ic(test_length(res, chunk_length))\n",
    "ic(test_sort(res, ee.results,sort_by=sort_by))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c491ab9-b8ac-4a18-a4ae-edc703bf7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diff(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6883690a-22c7-44a5-a9b3-ca5967eabfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.results.sort_values(['perc_emoji_of_stream','emoji_user_ratio'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a14494-2c98-465c-a7be-93fe7271c8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pillar Env",
   "language": "python",
   "name": "pillar_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
