{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pillaralgos import brain, algo1, algo2, algo3_0, algo3_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = json.load(open(\"prod/test/sample_data/sample_med.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-pomkos/.conda/envs/pillar_env/lib/python3.8/site-packages/pillaralgos/helpers/data_handler.py:278: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"hour\"] = i\n",
      "/home/jupyter-pomkos/.conda/envs/pillar_env/lib/python3.8/site-packages/pillaralgos/helpers/data_handler.py:279: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"chunk\"] = x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'startTime': 12177.737, 'endTime': 12293.058},\n",
       " {'startTime': 5856.98, 'endTime': 5974.813},\n",
       " {'startTime': 5608.555, 'endTime': 5726.127},\n",
       " {'startTime': 17734.164, 'endTime': 17853.51},\n",
       " {'startTime': 6612.054, 'endTime': 6729.235},\n",
       " {'startTime': 17117.536, 'endTime': 17237.341},\n",
       " {'startTime': 21114.107, 'endTime': 21233.315},\n",
       " {'startTime': 10677.524, 'endTime': 10786.595},\n",
       " {'startTime': 16380.996, 'endTime': 16499.338},\n",
       " {'startTime': 10823.715, 'endTime': 10943.506}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo3_0.run(data, min_=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-pomkos/.conda/envs/pillar_env/lib/python3.8/site-packages/pillaralgos/helpers/data_handler.py:278: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"hour\"] = i\n",
      "/home/jupyter-pomkos/.conda/envs/pillar_env/lib/python3.8/site-packages/pillaralgos/helpers/data_handler.py:279: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"chunk\"] = x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'startTime': 12177.737, 'endTime': 12293.058},\n",
       " {'startTime': 5856.98, 'endTime': 5974.813},\n",
       " {'startTime': 5608.555, 'endTime': 5726.127},\n",
       " {'startTime': 17734.164, 'endTime': 17853.51},\n",
       " {'startTime': 6612.054, 'endTime': 6729.235},\n",
       " {'startTime': 17117.536, 'endTime': 17237.341},\n",
       " {'startTime': 21114.107, 'endTime': 21233.315},\n",
       " {'startTime': 10677.524, 'endTime': 10786.595},\n",
       " {'startTime': 16380.996, 'endTime': 16499.338},\n",
       " {'startTime': 10823.715, 'endTime': 10943.506}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo3_0.run(data, min_=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-pomkos/.conda/envs/pillar_env/lib/python3.8/site-packages/pillaralgos/helpers/data_handler.py:278: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"hour\"] = i\n",
      "/home/jupyter-pomkos/.conda/envs/pillar_env/lib/python3.8/site-packages/pillaralgos/helpers/data_handler.py:279: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"chunk\"] = x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'startTime': 12177.737, 'endTime': 12293.058},\n",
       " {'startTime': 5856.98, 'endTime': 5974.813},\n",
       " {'startTime': 5608.555, 'endTime': 5726.127},\n",
       " {'startTime': 17734.164, 'endTime': 17853.51},\n",
       " {'startTime': 6612.054, 'endTime': 6729.235},\n",
       " {'startTime': 17117.536, 'endTime': 17237.341},\n",
       " {'startTime': 21114.107, 'endTime': 21233.315},\n",
       " {'startTime': 10677.524, 'endTime': 10786.595},\n",
       " {'startTime': 16380.996, 'endTime': 16499.338},\n",
       " {'startTime': 10823.715, 'endTime': 10943.506}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo3_0.run(data, min_=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'startTime': 765.512, 'endTime': 882.645},\n",
       " {'startTime': 1018.379, 'endTime': 1131.467},\n",
       " {'startTime': 0.0, 'endTime': 119.562},\n",
       " {'startTime': 891.677, 'endTime': 1008.99},\n",
       " {'startTime': 259.889, 'endTime': 375.413},\n",
       " {'startTime': 383.298, 'endTime': 495.599},\n",
       " {'startTime': 127.098, 'endTime': 234.249},\n",
       " {'startTime': 507.003, 'endTime': 626.884},\n",
       " {'startTime': 1138.629, 'endTime': 1256.19},\n",
       " {'startTime': 630.41, 'endTime': 741.233},\n",
       " {'startTime': 17734.164, 'endTime': 17853.51},\n",
       " {'startTime': 12177.737, 'endTime': 12293.058}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = [[{'startTime': 765.512, 'endTime': 882.645}, {'startTime': 1018.379, 'endTime': 1131.467}, {'startTime': 0.0, 'endTime': 119.562}, {'startTime': 891.677, 'endTime': 1008.99}, {'startTime': 259.889, 'endTime': 375.413}, {'startTime': 383.298, 'endTime': 495.599}, {'startTime': 127.098, 'endTime': 234.249}, {'startTime': 507.003, 'endTime': 626.884}, {'startTime': 1138.629, 'endTime': 1256.19}, {'startTime': 630.41, 'endTime': 741.233}], [{'startTime': 14415.312, 'endTime': 14421.943}, {'startTime': 21610.534, 'endTime': 21617.824}, {'startTime': 10801.908, 'endTime': 10811.585}, {'startTime': 26005.689, 'endTime': 26046.392}, {'startTime': 17974.932, 'endTime': 18028.889}, {'startTime': 19761.966, 'endTime': 19879.085}, {'startTime': 7152.677, 'endTime': 7201.808}, {'startTime': 17734.164, 'endTime': 17853.51}, {'startTime': 12177.737, 'endTime': 12293.058}, {'startTime': 25147.584, 'endTime': 25258.717}], [{'startTime': 12177.737, 'endTime': 12293.058}, {'startTime': 5856.98, 'endTime': 5974.813}, {'startTime': 5608.555, 'endTime': 5726.127}, {'startTime': 17734.164, 'endTime': 17853.51}, {'startTime': 6612.054, 'endTime': 6729.235}, {'startTime': 17117.536, 'endTime': 17237.341}, {'startTime': 21114.107, 'endTime': 21233.315}, {'startTime': 10677.524, 'endTime': 10786.595}, {'startTime': 16380.996, 'endTime': 16499.338}, {'startTime': 10823.715, 'endTime': 10943.506}], [{'startTime': 1018.379, 'endTime': 1131.467}, {'startTime': 1138.629, 'endTime': 1256.19}, {'startTime': 127.098, 'endTime': 234.249}, {'startTime': 0.0, 'endTime': 119.562}, {'startTime': 507.003, 'endTime': 626.884}, {'startTime': 259.889, 'endTime': 375.413}, {'startTime': 383.298, 'endTime': 495.599}, {'startTime': 765.512, 'endTime': 882.645}, {'startTime': 891.677, 'endTime': 1008.99}, {'startTime': 630.41, 'endTime': 741.233}]]\n",
    "\n",
    "results_df = pd.DataFrame(columns=['startTime','endTime'])\n",
    "for i in range(len(results)):\n",
    "    result = results[i]\n",
    "    result = pd.DataFrame(result)\n",
    "    results_df = results_df.append(result)\n",
    "\n",
    "common = list(results_df['startTime'].value_counts()[results_df['startTime'].value_counts() > 1].index)\n",
    "\n",
    "common_results = pd.DataFrame(columns=['startTime','endTime'])\n",
    "\n",
    "for i, row in results_df.iterrows():\n",
    "    if row['startTime'] in common:\n",
    "        common_results = common_results.append(row)\n",
    "\n",
    "common_results = common_results.drop_duplicates()\n",
    "\n",
    "new_json = []\n",
    "for i, row in common_results.iterrows():\n",
    "    new_json.append({'startTime':row['startTime'], 'endTime':row['endTime']})\n",
    "\n",
    "new_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "startTime\n",
       "0.000        2\n",
       "891.677      2\n",
       "12177.737    2\n",
       "17734.164    2\n",
       "127.098      2\n",
       "1018.379     2\n",
       "1138.629     2\n",
       "765.512      2\n",
       "630.410      2\n",
       "507.003      2\n",
       "383.298      2\n",
       "259.889      2\n",
       "16380.996    1\n",
       "25147.584    1\n",
       "21610.534    1\n",
       "21114.107    1\n",
       "19761.966    1\n",
       "17974.932    1\n",
       "17117.536    1\n",
       "10677.524    1\n",
       "14415.312    1\n",
       "10823.715    1\n",
       "10801.908    1\n",
       "7152.677     1\n",
       "6612.054     1\n",
       "5856.980     1\n",
       "5608.555     1\n",
       "26005.689    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.value_counts('startTime', sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New emoticon getter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pillaralgos.helpers import data_handler as dh\n",
    "\n",
    "data = json.load(open('data/sample_lg.json'))\n",
    "\n",
    "class emoticonExtractor:\n",
    "    def __init__(self, data, min_use='mean', limit=None):\n",
    "        \"\"\"\n",
    "        Gets data ready for emo extraction. Initializes dicts, lists, etc.\n",
    "        \n",
    "        input\n",
    "        -----\n",
    "        data: list\n",
    "            List of dictionaries, a json file opened with json.load(open(file))\n",
    "        min_use: str, int, None\n",
    "            'mean': Return only those emoticons who's count is > the mean occurrance\n",
    "            int: Return only those emoticons who's count is > X. Use 0 to not filter.\n",
    "        limit: int, None\n",
    "            int: Return only the top X emoticons (using df.head(X))\n",
    "            None: Return all emoticons\n",
    "        \"\"\"\n",
    "\n",
    "        big_df = dh.organize_twitch_chat(data)\n",
    "        print(big_df.iloc[-1, 0] - big_df.iloc[0, 0])\n",
    "        self.vid_id = data[0][\"content_id\"]\n",
    "        self.big_df = big_df\n",
    "        self.all_emos = (\n",
    "            []\n",
    "        )  # all unique emo_ids, later used to pd.Series(self.all_emos).value_counts()\n",
    "        self.limit = limit\n",
    "        self.min_use = min_use\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Coordinates all functions to return a dataset of top emojis used\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "\n",
    "        body_has_emo = self.big_df[~self.big_df[\"emoticons\"].isna()].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "\n",
    "        body_has_emo[\"emo_id_list\"] = body_has_emo[\"emoticons\"].apply(\n",
    "            lambda my_list: self.emo_extractor(my_list)\n",
    "        )\n",
    "\n",
    "        body_has_emo[\"emo_id_list\"].apply(lambda my_list: self.emo_saver(my_list))\n",
    "        body_has_emo[\"emo_loc\"] = body_has_emo[\"emoticons\"].apply(\n",
    "            lambda my_list: self.loc_extractor(my_list)\n",
    "        )\n",
    "\n",
    "        emo_data = body_has_emo[[\"emo_id_list\", \"emo_loc\", \"body\"]]\n",
    "        self.emo_data = emo_data\n",
    "\n",
    "        num_used = pd.Series(\n",
    "            self.all_emos\n",
    "        ).value_counts()  # count how many times each unique emo was used\n",
    "\n",
    "        num_used = num_used.reset_index()  # turn series to df, rename cols\n",
    "        num_used.columns = [\"emoji_id\", \"occurrance\"]\n",
    "\n",
    "        emo_dict = self.emo_id_matcher(\n",
    "            emo_data\n",
    "        )  # create a dictionary of emo_id:emo_name\n",
    "        num_used[\"emoji_name\"] = num_used[\"emoji_id\"].map(emo_dict)\n",
    "        num_used[\"label\"] = \"\"\n",
    "\n",
    "        if type(self.min_use) == str:\n",
    "            # grab everything greater than mean count\n",
    "            top_emoticons = num_used[num_used[\"occurrance\"] > num_used[\"occurrance\"].mean()]\n",
    "        elif type(self.min_use) == int:\n",
    "            # grab everything greater than X\n",
    "            top_emoticons = num_used[num_used[\"occurrance\"] > self.min_use]\n",
    "        else:\n",
    "            # otherwise return all results\n",
    "            top_emoticons = num_used\n",
    "            \n",
    "        if type(self.limit) == int:\n",
    "            # grab only the top X most used\n",
    "            top_emoticons = top_emoticons.head(limit)\n",
    "        else:\n",
    "            # return all results\n",
    "            top_emoticons = top_emoticons\n",
    "            \n",
    "        top_emoticons[\"vid_id\"] = self.vid_id\n",
    "        # reorganize columns\n",
    "        top_emoticons = top_emoticons[\n",
    "            [\"vid_id\", \"emoji_id\", \"occurrance\", \"emoji_name\", \"label\"]\n",
    "        ]\n",
    "\n",
    "        return top_emoticons\n",
    "\n",
    "    def emo_extractor(self, my_list):\n",
    "        \"\"\"\n",
    "        Helper function to grab emoticon id\n",
    "        \"\"\"\n",
    "        return [emo_dict[\"_id\"] for emo_dict in my_list]\n",
    "\n",
    "    def loc_extractor(self, my_list):\n",
    "        \"\"\"\n",
    "        Helper function to grab index location of emoticon in the body\n",
    "        \"\"\"\n",
    "        return [[emo_dict[\"begin\"], emo_dict[\"end\"]] for emo_dict in my_list]\n",
    "\n",
    "    def emo_saver(self, my_list):\n",
    "        \"\"\"\n",
    "        Helper function to extract all emo_ids from the list and append to self.all_emos\n",
    "        \"\"\"\n",
    "        for emo in my_list:\n",
    "            self.all_emos.append(emo)\n",
    "\n",
    "    def emo_id_matcher(self, emo_data):\n",
    "        \"\"\"\n",
    "        Matches the emoticon id to it's twitch-defined emoticon text\n",
    "        \"\"\"\n",
    "        emo_dict = {}\n",
    "        for i, row in emo_data.iterrows():\n",
    "            for x in range(len(row[\"emo_loc\"])):\n",
    "                loc = row[\"emo_loc\"][x]  # grab location\n",
    "                begin = loc[0]\n",
    "                end = loc[1] + 1\n",
    "                emoji_name = row[\"body\"][begin:end]  # extract emoji text\n",
    "                emoji_id = row[\"emo_id_list\"][x]\n",
    "\n",
    "                if emoji_id not in emo_dict.keys():\n",
    "                    emo_dict[emoji_id] = emoji_name\n",
    "        return emo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 days 10:57:21.037000\n"
     ]
    }
   ],
   "source": [
    "ee = emoticonExtractor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-ea49f88a0d3c>:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_emoticons[\"vid_id\"] = self.vid_id\n"
     ]
    }
   ],
   "source": [
    "df = ee.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to explore data, recreate bugs, solve bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pillaralgos import algo2\n",
    "import pillaralgos_dev as p_dev\n",
    "from pillaralgos_dev import dev_helpers as dev_help\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "buggy_file = '981828174'\n",
    "def bug_handler(buggy_file, algo):\n",
    "    '''\n",
    "    Simple function to run reported file and files in data folder through a function\n",
    "    '''\n",
    "    aws = p_dev.awsBucketAPI()\n",
    "    aws.save_specific_file(buggy_file)\n",
    "    data = json.load(open(f'data/{buggy_file}.json'))\n",
    "    try:\n",
    "        json_result = algo.run(data)\n",
    "    except Exception as e:\n",
    "        print(\"FAILED\")\n",
    "        print(e)\n",
    "\n",
    "    import os\n",
    "    files = os.listdir('data/')\n",
    "    new_files = [f for f in files if '.json' in f and 'big_data' not in f]\n",
    "\n",
    "    algoworked = []\n",
    "    algofailed = []\n",
    "    results = {}\n",
    "    for file in new_files:\n",
    "        try:\n",
    "            data = json.load(open(f'data/{file}'))\n",
    "            results[file] = algo.run(data)\n",
    "            algoworked.append(file)\n",
    "        except:\n",
    "            algofailed.append(file)\n",
    "    return algoworked, algofailed, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test creations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"pypi/prod/test/sample_data/sample_med.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pillaralgos.helpers import data_handler as dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pillaralgos import algo1, algo2, algo3_0, algo3_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_re1 = algo1.run(data,min_=0.5, limit=10, sort_by='rel',save_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-pomkos/.conda/envs/pillar_env/lib/python3.8/site-packages/pillaralgos/helpers/data_handler.py:278: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"hour\"] = i\n",
      "/home/jupyter-pomkos/.conda/envs/pillar_env/lib/python3.8/site-packages/pillaralgos/helpers/data_handler.py:279: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"chunk\"] = x\n"
     ]
    }
   ],
   "source": [
    "json_re2 = algo2.run(data,min_=0.5, limit=10,save_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pillaralgos.helpers import data_handler as dh\n",
    "\n",
    "data = json.load(open('data/sample_lg.json'))\n",
    "\n",
    "class emoticonExtractor:\n",
    "    def __init__(self, data, min_use='mean', limit=None):\n",
    "        \"\"\"\n",
    "        Gets data ready for emo extraction. Initializes dicts, lists, etc.\n",
    "        \n",
    "        input\n",
    "        -----\n",
    "        data: list\n",
    "            List of dictionaries, a json file opened with json.load(open(file))\n",
    "        min_use: str, int, None\n",
    "            'mean': Return only those emoticons who's count is > the mean occurrance\n",
    "            int: Return only those emoticons who's count is > X. Use 0 to not filter.\n",
    "        limit: int, None\n",
    "            int: Return only the top X emoticons (using df.head(X))\n",
    "            None: Return all emoticons\n",
    "        \"\"\"\n",
    "\n",
    "        big_df = dh.organize_twitch_chat(data)\n",
    "        print(big_df.iloc[-1, 0] - big_df.iloc[0, 0])\n",
    "        self.vid_id = data[0][\"content_id\"]\n",
    "        self.big_df = big_df\n",
    "        self.all_emos = (\n",
    "            []\n",
    "        )  # all unique emo_ids, later used to pd.Series(self.all_emos).value_counts()\n",
    "        self.limit = limit\n",
    "        self.min_use = min_use\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Coordinates all functions to return a dataset of top emojis used\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "\n",
    "        body_has_emo = self.big_df[~self.big_df[\"emoticons\"].isna()].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "\n",
    "        body_has_emo[\"emo_id_list\"] = body_has_emo[\"emoticons\"].apply(\n",
    "            lambda my_list: self.emo_extractor(my_list)\n",
    "        )\n",
    "\n",
    "        body_has_emo[\"emo_id_list\"].apply(lambda my_list: self.emo_saver(my_list))\n",
    "        body_has_emo[\"emo_loc\"] = body_has_emo[\"emoticons\"].apply(\n",
    "            lambda my_list: self.loc_extractor(my_list)\n",
    "        )\n",
    "\n",
    "        emo_data = body_has_emo[[\"emo_id_list\", \"emo_loc\", \"body\"]]\n",
    "        self.emo_data = emo_data\n",
    "\n",
    "        num_used = pd.Series(\n",
    "            self.all_emos\n",
    "        ).value_counts()  # count how many times each unique emo was used\n",
    "\n",
    "        num_used = num_used.reset_index()  # turn series to df, rename cols\n",
    "        num_used.columns = [\"emoji_id\", \"occurrance\"]\n",
    "\n",
    "        emo_dict = self.emo_id_matcher(\n",
    "            emo_data\n",
    "        )  # create a dictionary of emo_id:emo_name\n",
    "        num_used[\"emoji_name\"] = num_used[\"emoji_id\"].map(emo_dict)\n",
    "        num_used[\"label\"] = \"\"\n",
    "\n",
    "        if type(self.min_use) == str:\n",
    "            # grab everything greater than mean count\n",
    "            top_emoticons = num_used[num_used[\"occurrance\"] > num_used[\"occurrance\"].mean()]\n",
    "        elif type(self.min_use) == int:\n",
    "            # grab everything greater than X\n",
    "            top_emoticons = num_used[num_used[\"occurrance\"] > self.min_use]\n",
    "        else:\n",
    "            # otherwise return all results\n",
    "            top_emoticons = num_used\n",
    "            \n",
    "        if type(self.limit) == int:\n",
    "            # grab only the top X most used\n",
    "            top_emoticons = top_emoticons.head(limit)\n",
    "        else:\n",
    "            # return all results\n",
    "            top_emoticons = top_emoticons\n",
    "            \n",
    "        top_emoticons[\"vid_id\"] = self.vid_id\n",
    "        # reorganize columns\n",
    "        top_emoticons = top_emoticons[\n",
    "            [\"vid_id\", \"emoji_id\", \"occurrance\", \"emoji_name\", \"label\"]\n",
    "        ]\n",
    "\n",
    "        return top_emoticons\n",
    "\n",
    "    def emo_extractor(self, my_list):\n",
    "        \"\"\"\n",
    "        Helper function to grab emoticon id\n",
    "        \"\"\"\n",
    "        return [emo_dict[\"_id\"] for emo_dict in my_list]\n",
    "\n",
    "    def loc_extractor(self, my_list):\n",
    "        \"\"\"\n",
    "        Helper function to grab index location of emoticon in the body\n",
    "        \"\"\"\n",
    "        return [[emo_dict[\"begin\"], emo_dict[\"end\"]] for emo_dict in my_list]\n",
    "\n",
    "    def emo_saver(self, my_list):\n",
    "        \"\"\"\n",
    "        Helper function to extract all emo_ids from the list and append to self.all_emos\n",
    "        \"\"\"\n",
    "        for emo in my_list:\n",
    "            self.all_emos.append(emo)\n",
    "\n",
    "    def emo_id_matcher(self, emo_data):\n",
    "        \"\"\"\n",
    "        Matches the emoticon id to it's twitch-defined emoticon text\n",
    "        \"\"\"\n",
    "        emo_dict = {}\n",
    "        for i, row in emo_data.iterrows():\n",
    "            for x in range(len(row[\"emo_loc\"])):\n",
    "                loc = row[\"emo_loc\"][x]  # grab location\n",
    "                begin = loc[0]\n",
    "                end = loc[1] + 1\n",
    "                emoji_name = row[\"body\"][begin:end]  # extract emoji text\n",
    "                emoji_id = row[\"emo_id_list\"][x]\n",
    "\n",
    "                if emoji_id not in emo_dict.keys():\n",
    "                    emo_dict[emoji_id] = emoji_name\n",
    "        return emo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-pomkos/.conda/envs/pillar_env/lib/python3.8/site-packages/pillaralgos/helpers/data_handler.py:278: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"hour\"] = i\n",
      "/home/jupyter-pomkos/.conda/envs/pillar_env/lib/python3.8/site-packages/pillaralgos/helpers/data_handler.py:279: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"chunk\"] = x\n"
     ]
    }
   ],
   "source": [
    "json_re3 = algo3_5.run(data,min_=0.5, limit=10, goal='num_emo',save_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'startTime': 0.0, 'endTime': 119.562},\n",
       " {'startTime': 765.512, 'endTime': 882.645},\n",
       " {'startTime': 891.677, 'endTime': 1008.99},\n",
       " {'startTime': 259.889, 'endTime': 375.413},\n",
       " {'startTime': 127.098, 'endTime': 234.249},\n",
       " {'startTime': 383.298, 'endTime': 495.599},\n",
       " {'startTime': 630.41, 'endTime': 741.233},\n",
       " {'startTime': 1018.379, 'endTime': 1131.467},\n",
       " {'startTime': 507.003, 'endTime': 626.884},\n",
       " {'startTime': 1138.629, 'endTime': 1256.19}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_re3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pillar Env",
   "language": "python",
   "name": "pillar_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
