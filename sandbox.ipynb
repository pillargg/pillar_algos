{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New emoticon getter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pillaralgos.helpers import data_handler as dh\n",
    "\n",
    "data = json.load(open('data/sample_lg.json'))\n",
    "\n",
    "class emoticonExtractor:\n",
    "    def __init__(self, data, min_use='mean', limit=None):\n",
    "        \"\"\"\n",
    "        Gets data ready for emo extraction. Initializes dicts, lists, etc.\n",
    "        \n",
    "        input\n",
    "        -----\n",
    "        data: list\n",
    "            List of dictionaries, a json file opened with json.load(open(file))\n",
    "        min_use: str, int, None\n",
    "            'mean': Return only those emoticons who's count is > the mean occurrance\n",
    "            int: Return only those emoticons who's count is > X. Use 0 to not filter.\n",
    "        limit: int, None\n",
    "            int: Return only the top X emoticons (using df.head(X))\n",
    "            None: Return all emoticons\n",
    "        \"\"\"\n",
    "\n",
    "        big_df = dh.organize_twitch_chat(data)\n",
    "        print(big_df.iloc[-1, 0] - big_df.iloc[0, 0])\n",
    "        self.vid_id = data[0][\"content_id\"]\n",
    "        self.big_df = big_df\n",
    "        self.all_emos = (\n",
    "            []\n",
    "        )  # all unique emo_ids, later used to pd.Series(self.all_emos).value_counts()\n",
    "        self.limit = limit\n",
    "        self.min_use = min_use\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Coordinates all functions to return a dataset of top emojis used\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "\n",
    "        body_has_emo = self.big_df[~self.big_df[\"emoticons\"].isna()].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "\n",
    "        body_has_emo[\"emo_id_list\"] = body_has_emo[\"emoticons\"].apply(\n",
    "            lambda my_list: self.emo_extractor(my_list)\n",
    "        )\n",
    "\n",
    "        body_has_emo[\"emo_id_list\"].apply(lambda my_list: self.emo_saver(my_list))\n",
    "        body_has_emo[\"emo_loc\"] = body_has_emo[\"emoticons\"].apply(\n",
    "            lambda my_list: self.loc_extractor(my_list)\n",
    "        )\n",
    "\n",
    "        emo_data = body_has_emo[[\"emo_id_list\", \"emo_loc\", \"body\"]]\n",
    "        self.emo_data = emo_data\n",
    "\n",
    "        num_used = pd.Series(\n",
    "            self.all_emos\n",
    "        ).value_counts()  # count how many times each unique emo was used\n",
    "\n",
    "        num_used = num_used.reset_index()  # turn series to df, rename cols\n",
    "        num_used.columns = [\"emoji_id\", \"occurrance\"]\n",
    "\n",
    "        emo_dict = self.emo_id_matcher(\n",
    "            emo_data\n",
    "        )  # create a dictionary of emo_id:emo_name\n",
    "        num_used[\"emoji_name\"] = num_used[\"emoji_id\"].map(emo_dict)\n",
    "        num_used[\"label\"] = \"\"\n",
    "\n",
    "        if type(self.min_use) == str:\n",
    "            # grab everything greater than mean count\n",
    "            top_emoticons = num_used[num_used[\"occurrance\"] > num_used[\"occurrance\"].mean()]\n",
    "        elif type(self.min_use) == int:\n",
    "            # grab everything greater than X\n",
    "            top_emoticons = num_used[num_used[\"occurrance\"] > self.min_use]\n",
    "        else:\n",
    "            # otherwise return all results\n",
    "            top_emoticons = num_used\n",
    "            \n",
    "        if type(self.limit) == int:\n",
    "            # grab only the top X most used\n",
    "            top_emoticons = top_emoticons.head(limit)\n",
    "        else:\n",
    "            # return all results\n",
    "            top_emoticons = top_emoticons\n",
    "            \n",
    "        top_emoticons[\"vid_id\"] = self.vid_id\n",
    "        # reorganize columns\n",
    "        top_emoticons = top_emoticons[\n",
    "            [\"vid_id\", \"emoji_id\", \"occurrance\", \"emoji_name\", \"label\"]\n",
    "        ]\n",
    "\n",
    "        return top_emoticons\n",
    "\n",
    "    def emo_extractor(self, my_list):\n",
    "        \"\"\"\n",
    "        Helper function to grab emoticon id\n",
    "        \"\"\"\n",
    "        return [emo_dict[\"_id\"] for emo_dict in my_list]\n",
    "\n",
    "    def loc_extractor(self, my_list):\n",
    "        \"\"\"\n",
    "        Helper function to grab index location of emoticon in the body\n",
    "        \"\"\"\n",
    "        return [[emo_dict[\"begin\"], emo_dict[\"end\"]] for emo_dict in my_list]\n",
    "\n",
    "    def emo_saver(self, my_list):\n",
    "        \"\"\"\n",
    "        Helper function to extract all emo_ids from the list and append to self.all_emos\n",
    "        \"\"\"\n",
    "        for emo in my_list:\n",
    "            self.all_emos.append(emo)\n",
    "\n",
    "    def emo_id_matcher(self, emo_data):\n",
    "        \"\"\"\n",
    "        Matches the emoticon id to it's twitch-defined emoticon text\n",
    "        \"\"\"\n",
    "        emo_dict = {}\n",
    "        for i, row in emo_data.iterrows():\n",
    "            for x in range(len(row[\"emo_loc\"])):\n",
    "                loc = row[\"emo_loc\"][x]  # grab location\n",
    "                begin = loc[0]\n",
    "                end = loc[1] + 1\n",
    "                emoji_name = row[\"body\"][begin:end]  # extract emoji text\n",
    "                emoji_id = row[\"emo_id_list\"][x]\n",
    "\n",
    "                if emoji_id not in emo_dict.keys():\n",
    "                    emo_dict[emoji_id] = emoji_name\n",
    "        return emo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 days 10:57:21.037000\n"
     ]
    }
   ],
   "source": [
    "ee = emoticonExtractor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-ea49f88a0d3c>:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_emoticons[\"vid_id\"] = self.vid_id\n"
     ]
    }
   ],
   "source": [
    "df = ee.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old emoticon getter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 days 10:57:21.037000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-227a891fc555>:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_emoticons['vid_id'] = vid_id\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pillaralgos.helpers import data_handler as dh\n",
    "\n",
    "data = json.load(open(\"data/sample_lg.json\"))\n",
    "\n",
    "vid_id = data[0]['content_id']\n",
    "vid_id\n",
    "\n",
    "big_df = dh.organize_twitch_chat(data)\n",
    "print(big_df.iloc[-1,0] - big_df.iloc[0,0])\n",
    "\n",
    "def emo_extractor(my_list):\n",
    "    return [emo_dict['_id'] for emo_dict in my_list]\n",
    "\n",
    "\n",
    "def loc_extractor(my_list):\n",
    "    return [[emo_dict['begin'], emo_dict['end']] for emo_dict in my_list]\n",
    "\n",
    "all_emos = []\n",
    "def emo_saver(my_list):\n",
    "    for emo in my_list:\n",
    "        all_emos.append(emo)\n",
    "    return 'saved'\n",
    "\n",
    "emo_col = big_df['emoticons'].dropna().reset_index(drop=True)\n",
    "emo_id_list = emo_col.apply(lambda my_list: emo_extractor(my_list))\n",
    "emo_id_list.apply(lambda my_list: emo_saver(my_list))\n",
    "all_emos = pd.Series(all_emos)\n",
    "\n",
    "emo_loc = emo_col.apply(lambda my_list: loc_extractor(my_list))\n",
    "emo_body = big_df[~big_df['emoticons'].isna()]['body']\n",
    "\n",
    "emo_data = emo_loc.copy().reset_index()\n",
    "emo_data['body'] = emo_body.reset_index(drop=True)\n",
    "emo_data = emo_data.drop('index',axis=1)\n",
    "\n",
    "emo_data['id'] = emo_id_list\n",
    "\n",
    "emo_dict = {}\n",
    "\n",
    "for i, row in emo_data.iterrows():\n",
    "    for x in range(len(row['emoticons'])):\n",
    "        loc = row['emoticons'][x] # grab location\n",
    "        begin = loc[0]\n",
    "        end = loc[1] + 1\n",
    "        emoji_name = row['body'][begin:end] # extract emoji text\n",
    "        emoji_id = row['id'][x]\n",
    "        \n",
    "        if emoji_id not in emo_dict.keys():\n",
    "            emo_dict[emoji_id] = emoji_name\n",
    "\n",
    "num_used = all_emos.value_counts()\n",
    "\n",
    "num_used = num_used.reset_index()\n",
    "num_used.columns = ['emoji_id', 'occurrance']\n",
    "\n",
    "num_used['emoji_name'] = num_used['emoji_id'].map(emo_dict)\n",
    "\n",
    "num_used['label'] = ''\n",
    "top_emoticons = num_used[num_used['occurrance'] > num_used['occurrance'].mean()]\n",
    "top_emoticons['vid_id'] = vid_id\n",
    "top_emoticons = top_emoticons[['vid_id','emoji_id','occurrance','emoji_name','label']]\n",
    "\n",
    "# top_emoticons.to_csv(\"data/top_emoticons.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 55 entries, 0 to 54\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   vid_id      55 non-null     object\n",
      " 1   emoji_id    55 non-null     object\n",
      " 2   occurrance  55 non-null     int64 \n",
      " 3   emoji_name  55 non-null     object\n",
      " 4   label       55 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 2.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 55 entries, 0 to 54\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   vid_id      55 non-null     object\n",
      " 1   emoji_id    55 non-null     object\n",
      " 2   occurrance  55 non-null     int64 \n",
      " 3   emoji_name  55 non-null     object\n",
      " 4   label       55 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 2.6+ KB\n"
     ]
    }
   ],
   "source": [
    "top_emoticons.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(df == top_emoticons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to explore data, recreate bugs, solve bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pillaralgos import algo2\n",
    "import pillaralgos_dev as p_dev\n",
    "from pillaralgos_dev import dev_helpers as dev_help\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "buggy_file = '981828174'\n",
    "def bug_handler(buggy_file, algo):\n",
    "    '''\n",
    "    Simple function to run reported file and files in data folder through a function\n",
    "    '''\n",
    "    aws = p_dev.awsBucketAPI()\n",
    "    aws.save_specific_file(buggy_file)\n",
    "    data = json.load(open(f'data/{buggy_file}.json'))\n",
    "    try:\n",
    "        json_result = algo.run(data)\n",
    "    except Exception as e:\n",
    "        print(\"FAILED\")\n",
    "        print(e)\n",
    "\n",
    "    import os\n",
    "    files = os.listdir('data/')\n",
    "    new_files = [f for f in files if '.json' in f and 'big_data' not in f]\n",
    "\n",
    "    algoworked = []\n",
    "    algofailed = []\n",
    "    results = {}\n",
    "    for file in new_files:\n",
    "        try:\n",
    "            data = json.load(open(f'data/{file}'))\n",
    "            results[file] = algo.run(data)\n",
    "            algoworked.append(file)\n",
    "        except:\n",
    "            algofailed.append(file)\n",
    "    return algoworked, algofailed, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test creations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"pypi/prod/test/sample_data/sample_med.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pillaralgos.helpers import data_handler as dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pillaralgos import algo1, algo2, algo3_0, algo3_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_re1 = algo1.run(data,min_=0.5, limit=10, sort_by='rel',save_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-pomkos/.conda/envs/pillar_env/lib/python3.8/site-packages/pillaralgos/helpers/data_handler.py:278: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"hour\"] = i\n",
      "/home/jupyter-pomkos/.conda/envs/pillar_env/lib/python3.8/site-packages/pillaralgos/helpers/data_handler.py:279: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"chunk\"] = x\n"
     ]
    }
   ],
   "source": [
    "json_re2 = algo2.run(data,min_=0.5, limit=10,save_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pillaralgos.helpers import data_handler as dh\n",
    "\n",
    "data = json.load(open('data/sample_lg.json'))\n",
    "\n",
    "class emoticonExtractor:\n",
    "    def __init__(self, data, min_use='mean', limit=None):\n",
    "        \"\"\"\n",
    "        Gets data ready for emo extraction. Initializes dicts, lists, etc.\n",
    "        \n",
    "        input\n",
    "        -----\n",
    "        data: list\n",
    "            List of dictionaries, a json file opened with json.load(open(file))\n",
    "        min_use: str, int, None\n",
    "            'mean': Return only those emoticons who's count is > the mean occurrance\n",
    "            int: Return only those emoticons who's count is > X. Use 0 to not filter.\n",
    "        limit: int, None\n",
    "            int: Return only the top X emoticons (using df.head(X))\n",
    "            None: Return all emoticons\n",
    "        \"\"\"\n",
    "\n",
    "        big_df = dh.organize_twitch_chat(data)\n",
    "        print(big_df.iloc[-1, 0] - big_df.iloc[0, 0])\n",
    "        self.vid_id = data[0][\"content_id\"]\n",
    "        self.big_df = big_df\n",
    "        self.all_emos = (\n",
    "            []\n",
    "        )  # all unique emo_ids, later used to pd.Series(self.all_emos).value_counts()\n",
    "        self.limit = limit\n",
    "        self.min_use = min_use\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Coordinates all functions to return a dataset of top emojis used\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "\n",
    "        body_has_emo = self.big_df[~self.big_df[\"emoticons\"].isna()].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "\n",
    "        body_has_emo[\"emo_id_list\"] = body_has_emo[\"emoticons\"].apply(\n",
    "            lambda my_list: self.emo_extractor(my_list)\n",
    "        )\n",
    "\n",
    "        body_has_emo[\"emo_id_list\"].apply(lambda my_list: self.emo_saver(my_list))\n",
    "        body_has_emo[\"emo_loc\"] = body_has_emo[\"emoticons\"].apply(\n",
    "            lambda my_list: self.loc_extractor(my_list)\n",
    "        )\n",
    "\n",
    "        emo_data = body_has_emo[[\"emo_id_list\", \"emo_loc\", \"body\"]]\n",
    "        self.emo_data = emo_data\n",
    "\n",
    "        num_used = pd.Series(\n",
    "            self.all_emos\n",
    "        ).value_counts()  # count how many times each unique emo was used\n",
    "\n",
    "        num_used = num_used.reset_index()  # turn series to df, rename cols\n",
    "        num_used.columns = [\"emoji_id\", \"occurrance\"]\n",
    "\n",
    "        emo_dict = self.emo_id_matcher(\n",
    "            emo_data\n",
    "        )  # create a dictionary of emo_id:emo_name\n",
    "        num_used[\"emoji_name\"] = num_used[\"emoji_id\"].map(emo_dict)\n",
    "        num_used[\"label\"] = \"\"\n",
    "\n",
    "        if type(self.min_use) == str:\n",
    "            # grab everything greater than mean count\n",
    "            top_emoticons = num_used[num_used[\"occurrance\"] > num_used[\"occurrance\"].mean()]\n",
    "        elif type(self.min_use) == int:\n",
    "            # grab everything greater than X\n",
    "            top_emoticons = num_used[num_used[\"occurrance\"] > self.min_use]\n",
    "        else:\n",
    "            # otherwise return all results\n",
    "            top_emoticons = num_used\n",
    "            \n",
    "        if type(self.limit) == int:\n",
    "            # grab only the top X most used\n",
    "            top_emoticons = top_emoticons.head(limit)\n",
    "        else:\n",
    "            # return all results\n",
    "            top_emoticons = top_emoticons\n",
    "            \n",
    "        top_emoticons[\"vid_id\"] = self.vid_id\n",
    "        # reorganize columns\n",
    "        top_emoticons = top_emoticons[\n",
    "            [\"vid_id\", \"emoji_id\", \"occurrance\", \"emoji_name\", \"label\"]\n",
    "        ]\n",
    "\n",
    "        return top_emoticons\n",
    "\n",
    "    def emo_extractor(self, my_list):\n",
    "        \"\"\"\n",
    "        Helper function to grab emoticon id\n",
    "        \"\"\"\n",
    "        return [emo_dict[\"_id\"] for emo_dict in my_list]\n",
    "\n",
    "    def loc_extractor(self, my_list):\n",
    "        \"\"\"\n",
    "        Helper function to grab index location of emoticon in the body\n",
    "        \"\"\"\n",
    "        return [[emo_dict[\"begin\"], emo_dict[\"end\"]] for emo_dict in my_list]\n",
    "\n",
    "    def emo_saver(self, my_list):\n",
    "        \"\"\"\n",
    "        Helper function to extract all emo_ids from the list and append to self.all_emos\n",
    "        \"\"\"\n",
    "        for emo in my_list:\n",
    "            self.all_emos.append(emo)\n",
    "\n",
    "    def emo_id_matcher(self, emo_data):\n",
    "        \"\"\"\n",
    "        Matches the emoticon id to it's twitch-defined emoticon text\n",
    "        \"\"\"\n",
    "        emo_dict = {}\n",
    "        for i, row in emo_data.iterrows():\n",
    "            for x in range(len(row[\"emo_loc\"])):\n",
    "                loc = row[\"emo_loc\"][x]  # grab location\n",
    "                begin = loc[0]\n",
    "                end = loc[1] + 1\n",
    "                emoji_name = row[\"body\"][begin:end]  # extract emoji text\n",
    "                emoji_id = row[\"emo_id_list\"][x]\n",
    "\n",
    "                if emoji_id not in emo_dict.keys():\n",
    "                    emo_dict[emoji_id] = emoji_name\n",
    "        return emo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-pomkos/.conda/envs/pillar_env/lib/python3.8/site-packages/pillaralgos/helpers/data_handler.py:278: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"hour\"] = i\n",
      "/home/jupyter-pomkos/.conda/envs/pillar_env/lib/python3.8/site-packages/pillaralgos/helpers/data_handler.py:279: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"chunk\"] = x\n"
     ]
    }
   ],
   "source": [
    "json_re3 = algo3_5.run(data,min_=0.5, limit=10, goal='num_emo',save_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'startTime': 0.0, 'endTime': 119.562},\n",
       " {'startTime': 765.512, 'endTime': 882.645},\n",
       " {'startTime': 891.677, 'endTime': 1008.99},\n",
       " {'startTime': 259.889, 'endTime': 375.413},\n",
       " {'startTime': 127.098, 'endTime': 234.249},\n",
       " {'startTime': 383.298, 'endTime': 495.599},\n",
       " {'startTime': 630.41, 'endTime': 741.233},\n",
       " {'startTime': 1018.379, 'endTime': 1131.467},\n",
       " {'startTime': 507.003, 'endTime': 626.884},\n",
       " {'startTime': 1138.629, 'endTime': 1256.19}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_re3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pillar Env",
   "language": "python",
   "name": "pillar_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
